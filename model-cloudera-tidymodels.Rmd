---
layout: page
title: xwMOOC 모형
subtitle: "고객이탈 - `tidymodels`"
author:
    name: xwMOOC
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')

```


# 당근(`caret`)에서 파스닙(`parsnip`) [^about-parsnip] [^business-science-parsnip] [^business-science-parsnip] {#about-parsnip}

[^about-parsnip]: 파스닙(`parsnip`): 명사, 식물, 미나릿과의 한해살이 또는 두해살이풀. 유라시아 원산으로 17세기 초 미국에 도입되어 귀화되었다. 춘파하면 여름이 끝날 무렵에는 녹말 성분이 많고 충실한 뿌리를 얻을 수 있다. 달콤한 맛이 나고, 보통 채소로 요리해 먹는다.

[^business-science-parsnip]: [Diego Usai on November 18, 2019, "Customer Churn Modeling using Machine Learning with parsnip"](https://www.business-science.io/code-tools/2019/11/18/parsnip-churn-classification-machine-learning.html)

당근(caret)은 이제 유지관리상태로 접어들고 최근 활발히 개발되고 있는 것이 `tidymodels`라는 체계 아래 기계학습모형에 대한 대대적인 해체작업과 재창조 작업이 일어나고 있다.

- 기계학습 예측모형에 사용되는 모듈 팩키지 
    -`skimr`: 탐색적 데이터 분석
    - `recipes`: 데이터 전처리
    - `rsample`: 훈련/시험 표본 분리 및 교차검증(cross-validation) 표본
    - `parsnip`: R 기계학습 API, 파이썬 scikit-learn에 대응됨.
    - `ranger`: Random Forest 기계학습 팩키지
    - `yardstick`: 예측모형 성능 평가

![고객이탈모형 `tidymodels` 작업흐름](fig/parsnip_workflow.jpg)

# 환경설정 {#tidymodels-parsnip-setup}

앞서 정의한 팩키지를 가지오고 데이터도 불러온다.

```{r parsnip-telco}
library(tidyverse)   
library(tidymodels)  
library(skimr)       
library(knitr)

telco <- read_csv("data/WA_Fn-UseC_-Telco-Customer-Churn.csv")

telco %>% head() %>% kable()
```


# EDA {#tidymodels-parsnip-EDA}

`skimr` 팩키지로 탐색적 데이터 분석 작업을 수행한다.

```{r parsnip-telco-EDA}
telco %>% skim()
```

# 데이터 정제 {#tidymodels-parsnip-clean}

`cusomterID`는 유일무이한 값이라 제외하고 결측값이 일부 있어 `drop_na()` 함수로 제거한다.

```{r parsnip-telco-clean}
telco <- telco %>% 
  select(-customerID) %>% 
  drop_na()
```


# 예측 모형 개발 - GLM {#tidymodels-glm}

## 훈련/시험 데이터셋 {#tidymodels-glm-train-testing}

훈련/시험 데이터셋으로 나누는데 `rsample` 팩키지 `initial_split()` 함수를 사용한다.
그리고, 훈련은 `training()` 함수로, 시험은 `testing()` 함수를 사용해서 각각 준비시킨다.

```{r parsnip-glm}
train_test_split <-
    rsample::initial_split(
        data = telco,     
        prop = 0.80   
    ) 

train_tbl <- train_test_split %>% training() 
test_tbl  <- train_test_split %>% testing() 
```

## 피처 공학(feature engineering) {#tidymodels-feature-engineer}

`recipes` 팩키지는 요리과정을 은유로 사용하기는데 기계학습 예측모형을 개발할 때 많이 사용하는 결측값 처리, 척도 통일, 가변수 처리, 상관관계가 높은 변수 제거 등을 이를 통해서 작업할 수 있다.

```{r feature-engineering-telco}
churn_recipe <- function(dataset) {
    recipe(Churn ~ ., data = dataset) %>%
        step_string2factor(all_nominal(), -all_outcomes()) %>%
        prep(data = dataset)
}

recipe_prepped <- churn_recipe(dataset = train_tbl)

train_baked <- bake(recipe_prepped, new_data = train_tbl)
test_baked  <- bake(recipe_prepped, new_data = test_tbl)
```

## 모형 적합 {#tidymodels-fit-glm}

파이썬 `scikit-learn`과 유사한 역할을 수행하는 `parsnip`을 활용하여 기계학습 예측모형을 개발한다.

```{r telco-fit-glm}
logistic_glm <- logistic_reg(mode = "classification") %>%
    set_engine("glm") %>%
    fit(Churn ~ ., data = train_baked)
```

## 모형 평가 {#tidymodels-fit-glm-assess}

모형평가를 위해서 시험데이터에 대해서 예측값을 뽑아내고 이를 실제값과 비교할 수 있도록 데이터프레임을 제작한다.

```{r telco-fit-glm-assessment}
logistic_pred <- logistic_glm %>%
    predict(new_data = test_baked) %>%
    bind_cols(test_baked %>% select(Churn))

logistic_pred %>% head() %>% kable()
```

혼동행렬(confusion matrix)를 구해서 이해하기 쉬운 표형태로 만들어 낸다.

```{r telco-fit-glm-assessment-confusion}
logistic_pred %>%
    conf_mat(Churn, .pred_class) %>%
    pluck(1) %>%
    as_tibble() %>% 
    spread(Prediction, n)
```

`yardstick` 팩키지 `metrics` 함수를 사용해서 정확도(accuracy)를 통해 예측함수 성능을 비교한다.

```{r telco-fit-glm-assessment-metrics}
logistic_pred %>%
  yardstick::metrics(Churn, .pred_class)
```

그외 `precision`과 `recall`을 사용해서 이탈할 것으로 예측한 고객 중 얼마나 떠났는지, 실제 이탈한 고객 중 얼마나 떠났는지 맞추는 측도도 함께 계산한다.

```{r telco-fit-glm-assessment-metrics-practice}
tibble(
  "precision" = precision(logistic_pred, Churn, .pred_class) %>% 
    select(.estimate),
  "recall"    = recall(logistic_pred, Churn, .pred_class) %>% 
  select(.estimate),
  "F1"    = f_meas(logistic_pred, Churn, .pred_class) %>% 
  select(.estimate))
```

# Random Forest - `ranger` {#tidymodels-ranger}

## 교차검증 표본 {#tidymodels-ranger-cv}

10 교차검증 표본을 `vfold_cv()` 함수로 생성한다.

```{r random-forest-telco}
cross_val_tbl <- vfold_cv(train_tbl, v = 10)
cross_val_tbl

cross_val_tbl %>% pluck("splits", 1)
```

## `ranger` 모형 적합 {#tidymodels-ranger-fit}

`fit_ranger_model()` 함수를 만들어서, `ranger` 모델에 적합을 시킨다.

```{r random-forest-telco-fit}
fit_ranger_model <- function(split, id, try, tree) {
    
    analysis_set <- split %>% analysis()
    analysis_prepped <- analysis_set %>% churn_recipe()
    analysis_baked <- analysis_prepped %>% bake(new_data = analysis_set)
    
    model_rf <-
        rand_forest(
            mode = "classification",
            mtry = try,
            trees = tree
        ) %>%
        set_engine("ranger",
                   importance = "impurity"
        ) %>%
        fit(Churn ~ ., data = analysis_baked)
    
    assessment_set     <- split %>% assessment()
    assessment_prepped <- assessment_set %>% churn_recipe()
    assessment_baked   <- assessment_prepped %>% bake(new_data = assessment_set)
    
    tibble(
        "id" = id,
        "truth" = assessment_baked$Churn,
        "prediction" = model_rf %>%
            predict(new_data = assessment_baked) %>%
            unlist()
    )
}

pred_rf <- map2_df(
    .x = cross_val_tbl$splits,
    .y = cross_val_tbl$id,
    ~ fit_ranger_model(split = .x, id = .y, try = 3, tree = 200)
)

head(pred_rf)
```

## `ranger` 성능 평가 {#tidymodels-ranger-fit-assess}

`ranger` 예측모형 객체 &rarr; `conf_mat()` &rarr; `summary()`를 파이프로 연결시켜 예측모형 성능지표를 추출한다.

```{r random-forest-telco-assess}
pred_rf %>%
    conf_mat(truth, prediction) %>%
    summary() %>%
    select(-.estimator) %>%
    filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>%
    kable()
```

# 두 모형 성능 비교 {#tidymodels-model-comparison}

```{r tidymodels-comparison}
glm_metrics <- logistic_pred %>%
    conf_mat(Churn, .pred_class) %>%
    summary() %>%
    select(-.estimator) %>%
    filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>% 
    rename(GLM = .estimate)

rf_metrics <- pred_rf %>%
    conf_mat(truth, prediction) %>%
    summary() %>%
    select(-.estimator) %>%
    filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) %>% 
    rename(RF = .estimate)

inner_join(glm_metrics, rf_metrics) %>% 
  kable()
```

