---
layout: page
title: "xwMOOC 모형 - `tidymodels`"
subtitle: "`parsnip` + `tidytext` + `textrecipes`"
author:
  name: "[Tidyverse Korea](https://www.facebook.com/groups/tidyverse/)"
  url: https://www.facebook.com/groups/tidyverse/
  affiliation: Tidyverse Korea
  affiliation_url: https://www.facebook.com/groups/tidyverse/
date: "`r Sys.Date()`"
output:
  html_document: 
    include:
      after_body: footer.html
      before_body: header.html
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
bibliography: bibliography_model.bib
csl: biomed-central.csl
urlcolor: blue
linkcolor: bluee
editor_options: 
  chunk_output_type: console
---
 
``` {r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')
```

# 텍스트 저자 분류 [^tidymodels-text-classification] [^text-tidymodels] {#tidymodels-text-classification}

[^tidymodels-text-classification]: [EMIL HVITFELDT, "Authorship classification with tidymodels and textrecipes"](https://www.hvitfeldt.me/blog/authorship-classification-with-tidymodels-and-textrecipes/)

[^text-tidymodels]: [EMIL HVITFELDT, "Text Classification with Tidymodels"](https://www.hvitfeldt.me/blog/text-classification-with-tidymodels/)

고전작가 중 제인 오스틴 '오만과 편견'과 유사한 길이를 갖는 코난 도일의 '셜록 홈즈의 모험'을 구텐베르그 웹사이트에서 가져와서 작가를 판별하는 예측모형을 구축해본다.

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
</style>
<div class = "blue">

**[한국인이 가장 사랑하는 세계적인 작가는? - 현존 작가 베르나르 베르베르, 고전작가 생텍쥐페리](http://www.econovill.com/news/articleView.html?idxno=219074)**

'불멸의 고전 작가' 투표에서는 '어린 왕자'의 앙투안 드 생텍쥐페리가 5,513표(7%)를 얻어 최고의 영예를 안았다. '셜록 홈즈' 시리즈의 아서 코난 도일은 4,366표(5.6%)로 2위, '레 미제라블'의 빅토르 위고는 4,266표(5.4%)로 3위를 차지했다. 이어 헤르만 헤세가 5.4%로 4위에 올랐고, 윌리엄 셰익스피어(5.3%), 어니스트 헤밍웨이(5.1%), 제인 오스틴(4.7%), 조지 오웰(3.9%) 등이 5~8위로 뒤를 이었다. 

</div>

# 데이터 가져오기 {#tidymodels-text-data}

구텐베르그에 모든 고전 영문소설이 공개된 것은 아니다. 따라서 몇분정도 유명한 서양작가의 소설을 찾아 코난 도일과 제인 오스틴의 소설을 대표로 다운로드 받아 이를 분류하는 모형을 개발해 본다.

```{r gutenberg-dataset}
library(tidyverse)
library(tidymodels)
library(tidytext)

## 텍스트 데이터
library(gutenbergr)

titles <- c(
  "Pride and Prejudice",
  "The Adventures of Sherlock Holmes")

books <- gutenberg_works(title %in% titles) %>%
  gutenberg_download(meta_fields = "title") %>%
  mutate(title = as.factor(title)) %>%
  select(-gutenberg_id)

books %>% 
  count(title)
```

# 훈련/시험 데이터 쪼개기 [^useR2020-tutorial] {#tidytext-split}

[^useR2020-tutorial]: [Emil Hvitfeldt, Julia Silge (24 July 2020), "Predictive modeling with text using tidy data principles", Materials for our useR! 2020 ](https://github.com/EmilHvitfeldt/useR2020-text-modeling-tutorial)

`rsample` 팩키지 `initial_split()` 함수로 훈련/시험 데이터를 7:3으로 쪼갠다.

```{r tidytext-preprocessing}
books_split <- initial_split(books, 
                             strata = "title", 
                             p = 0.70)

train_df <- training(books_split)
test_df <- testing(books_split)
```

# 피처 공학(feature engineering) {#tidytext-feature-engineering}

`textrecipes` 팩키지를 사용하여 텍스트에 대한 전처리 작업을 수행하여 피처 공학을 통해 `basetable`을 제작한다.
[`textrecipes`](https://github.com/tidymodels/textrecipes)는 토큰화, 불용어 제거 등이 포함된다. `max_tokens = tune()`를 도입하여 최대 토큰수도 튜닝하여 결정한다.

```{r tidytext-fe}
library(textrecipes)
library(stopwords)

title_rec <- recipe(title ~ ., data = train_df) %>%
  step_filter(text != "") %>% 
  step_tokenize(text) %>% 
  step_ngram(text, num_tokens = 2, min_num_tokens = 1) %>%
  step_tokenfilter(text,  max_tokens = 250) %>%
  step_tfidf(text)

title_rec %>% prep() %>% juice()
```


# 모형 선정 {#tidytext-spec}

`XGBoost` 예측모형을 저작 분류문제를 해결하는데 사용할 수 도 있는데, 
텍스트 데이터에 기반하여 분류기를 제작할 경우 다음 모형이 상대적으로 컴퓨팅 자원도 적게 소모하면서 더 좋은 성능을 보여준다.
이유는 Basetable 모형행렬이 매우 성긴 구조를 갖기 때문에 다음 모형이 XGBoost, Random Forest 와 같은 나무모형보다 권장된다.

- `glmnet`: Regularized linear models
- SVM: Support vector machines
- 나이브 베이즈: naive Bayes

```{r tidytext-model-spec}
lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_mode("classification") %>%
  set_engine("glmnet")
lasso_spec
```


## CV & 초모수 격자탐색 {#tidytext-spec-hyper-parameter}

`glmnet` Lasso 회귀모형을 적합시킬 때 초모수(hyper paramter) 하나를 특정해야한다. 
이를 위해서 다음과 같이 격자탐색기를 특정하고 이를 교차검증표본(Cross Validation)으로 초모수를 특정한다.


```{r tidytext-model-hyper-parameter}
param_grid <- grid_regular(
  penalty(range = c(-4, 0)),
  levels = 10
)
param_grid
```

초모수 특정을 위해서 빵과 버터, 김치와 밥처럼 함께 따라다니는 것이 교차검증표본(Cross Validation)이다.
`vfold_cv()` 함수를 가장 많이 사용한다. 


```{r tidytext-model-vfolds}
title_folds <- vfold_cv(train_df, strata = title)
title_folds
```


# 작업흐름(workflow) {#setup-workflow-title}

`workflow()`를 통해 앞서 훈련/시험 분리, 전처리, 예측모형, 모형 공식 등을 모듈화시킨 것을 한곳으로 연결시켜 자동화한다.


```{r tidytext-workflow-automation}
title_wf <- workflow() %>%
  add_recipe(title_rec) %>%
  add_model(lasso_spec)

title_wf
```

## 초모수 특정 {#setup-workflow-title}

`glmnet` 모형에서 특정되지 않는 `penalty = `를 CV로 튜닝하여 최적 초모수를 잡아낸다.

```{r tidytext-workflow-tune, eval = FALSE}
library(tictoc)

tic()
doParallel::registerDoParallel() #윈도우에서 오류가 생김

lasso_rs <- tune_grid(
  title_wf,
  resamples = title_folds,
  grid = param_grid, 
  control = control_grid(save_pred = TRUE, verbose = TRUE)
) 
toc()

lasso_rs %>% 
  write_rds("data/lasso_rs.rds")
```


# 모형 평가 {#tidytext-evaluate}

2020-08-08 현재 윈도우10에서 돌릴 경우 여러 문제가 생기기 때문에 가능하면 맥이나 리눅스에서 직접 돌리는 것이 문제의 본질에 집중할 수 있을 것으로 보인다. 맥에서 돌린 모형 결과를 윈도우에서 가져와서 나머지 작업을 이어서 한다.


```{r tidytext-evaluate-lasso}
lasso_rs <- read_rds("data/lasso_rs.rds")
lasso_rs %>% 
  collect_metrics()
```


## 라소모형 시각화 {#visualize-lasso-penality}

`autoplot()` 혹은 `select_best()` 함수를 사용해서 초모수 튜닝 결과를 다음 후속 모형평가와 예측에 사용할 수 있다.

```{r visualize-lasso-penality-paramter}
lasso_rs %>% 
  autoplot()
```

## ROC 시각화 {#visualize-rocauc}

ROC 곡선을 그려 모형 성능에 대한 시각화 작업을 수행한다.

```{r visualize-roc}
best_roc_auc <- select_best(lasso_rs, "roc_auc")
best_roc_auc
```

`collect_predictions()` 함수는 앞선 예측값에 더하여 ROC 곡선생성에 필요한 확률값도 함께 포함하고 있다.
이를 입력값으로 삼아 `roc_curve()`를 그릴 수 있다.

```{r tidytext-evaluate-prediction}
collect_predictions(lasso_rs, parameters = best_roc_auc) %>%
  group_by(id) %>%
  roc_curve(truth = title, `.pred_Pride and Prejudice`) %>%
  autoplot()
```

예측모형 성능에 대한 주요 측도를 뽑아본다.

```{r tidytext-performance-metrics}
collect_predictions(lasso_rs, parameters = best_roc_auc) %>%
  conf_mat(truth = title, `.pred_class`) %>% 
  summary() %>% 
  select(-.estimator) %>%
  filter(.metric %in% c("accuracy", "precision", "recall", "f_meas")) 
```

`roc_curve()`와 `autoplot()`을 쭉 연결시켜 시각화를 빠르게 수행한다.

```{r tidytext-roc-curve-fit}
collect_predictions(lasso_rs, parameters = best_roc_auc) %>%
  roc_curve(title, `.pred_Pride and Prejudice`) %>%
  autoplot()
```


# 변수 중요도 {#textrecipe-variable-importance}

`title_wf`에 초모수 튜닝 결과를 반영시켜 최종 작업흐름을 완성한다.
이를 위해서 사용되는 함수가 `finalize_workflow()`다.

```{r final-model}
wf_spec_final <- finalize_workflow(title_wf, best_roc_auc)
wf_spec_final
```


`vip` 팩키지를 동원해서 변수중요도를 추출하는데 먼저 데이터프레임을 준비한다.

```{r model-final-vip}
library(vip)

vi_data <- wf_spec_final %>%
  fit(train_df) %>%
  pull_workflow_fit() %>%
  vi(lambda = best_roc_auc$penalty) %>%
  mutate(Variable = str_remove_all(Variable, "tfidf_text_")) %>%
  filter(Importance != 0)

vi_data
```

오만과 편견(Pride and Prejudice), 셜록홈즈의 모험(The Adventures of Sherlock Holmes)으로 분류하는데 큰 영향을 주는 변수를 상위 20개만 뽑아 시각화해서 서로 비교해보자.


```{r visualize-variable-importance}
vi_data %>%
  mutate( Importance = abs(Importance)) %>%
  filter(Importance != 0) %>%
  group_by(Sign) %>%
  top_n(20, Importance) %>%
  ungroup() %>%
  mutate(Sign = factor(Sign, c("POS", "NEG"), c("Holmes", "Pride"))) %>%
  ggplot(aes(x = Importance,y = fct_reorder(Variable, Importance), fill = Sign)) +
    geom_col(show.legend = FALSE) +
    scale_x_continuous(expand = c(0, 0)) +
    facet_wrap(~Sign, scales = "free") +
    labs(y = NULL )
```


# 최종 모형 및 성능 {#textrecipe-deploy}

이제 예측모형을 마지막 배포하기에 앞서 시험데이터(test data)를 통해서 최종 모형 성능화 예측모형을 완성시켜보자.

```{r visualize-deploy-predictive-model}
final_fit <- last_fit(wf_spec_final, books_split)
final_fit
```

초모수 튜닝까지 끝난 최종 모형에 대한 평가측도는 다음과 같다.

```{r deploy-model-metrics}
final_fit %>%
  collect_metrics()
```

`collect_predicions()` 함수와 `roc_curve()` 함수를 사용해서 시각화하자.

```{r autoplot_roc-final-visualize}
final_fit %>%
  collect_predictions() %>%
  roc_curve(title, `.pred_Pride and Prejudice`) %>%
  autoplot()
```

