---
layout: page
title: "xwMOOC 모형: `tidymodels`"
subtitle: "예측모형 GDPR: `tidymodels`"
author:
  - name: "[Tidyverse Korea](https://www.facebook.com/groups/tidyverse/)"
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
    affiliation_url: https://www.facebook.com/groups/tidyverse/
date: "`r Sys.Date()`"
output:
  html_document: 
    include:
      after_body: footer.html
      before_body: header.html
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
bibliography: bibliography_model.bib
csl: biomed-central.csl
urlcolor: blue
linkcolor: blue
editor_options: 
  chunk_output_type: console
---
 
``` {r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, fig.align = 'center')

```

# 데이터셋 {#tidytuesday-dataset}

[`tidytuesdayR`](https://github.com/thebioengineer/tidytuesdayR) 팩키지는 기존 Tidy Tuesday 데이터 과학 해킹데이터를 정리한 데이터 팩키지다. [GDPR Fines](https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-04-21) 데이터를 다운로드 받아 데이터 정제 작업을 수행하고 벌금 예측모형을 개발한다. `tidytuesdayR`를 사용해서 데이터를 가져오려고 했으나 [`tt_load()` invalid multibyte string error #64](https://github.com/thebioengineer/tidytuesdayR/issues/64) 이슈가 발생되어 직접 웹사이트에서 데이터를 가져오도록 한다.

```{r tidytuesday-dataset}
library(tidytuesdayR)
library(tidyverse)
library(tidymodels)

fines <- read_tsv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_violations.tsv")
gdpr_text <- read_tsv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_text.tsv")

fines
```

# 데이터셋 {#tidytuesday-dataset}

예측모형 개발을 위한 `Basetable` 생성에 대한 전처리 및 피처 공학(feature engineering) 관련 사항은 [Modeling #TidyTuesday GDPR violations with tidymodels](https://juliasilge.com/blog/gdpr-violations/)을 참고한다.

```{r tidytuesday-dataset-feature-engineering}
gdpr_tidy <- fines %>%
  transmute(id,
    price,
    # country = name,
    article_violated,
    articles = str_extract_all(article_violated, "Art.[:digit:]+|Art. [:digit:]+")
  ) %>%
  mutate(total_articles = map_int(articles, length)) %>%
  unnest(articles) %>%
  add_count(articles) %>%
  filter(n > 10) %>%
  select(-n)

gdpr_df <- gdpr_tidy %>%
  mutate(value = 1) %>%
  select(-article_violated) %>%
  pivot_wider(
    names_from = articles, values_from = value,
    values_fn = list(value = max), values_fill = list(value = 0)
  ) %>%
  janitor::clean_names()

gdpr_df
```

## 훈련/시험 전처리 {#gdpr-feature-engineering}

훈련/시험 데이터로 나누고 `recipes` 팩키지를 활용하여 feature engineering 작업을 수행한다.

```{r split-sample-fe}
# 훈련/시험 데이터셋
tidy_split <- initial_split(gdpr_df, prop = 0.8, strata = price)

tidy_train <- training(tidy_split)
tidy_test  <- testing(tidy_split)

# Feature Engineering

gdpr_rec <- recipe(price ~ ., data = gdpr_df) %>%
  update_role(id, new_role = "id") %>%
  step_log(price, base = 10, offset = 1, skip = TRUE) %>%
  # step_other(country, threshold = 0.1, other = "Other") %>%
  step_dummy(all_nominal()) %>%
  step_zv(all_predictors()) %>% 
  prep()

gdpr_rec %>% juice()
```

# 예측모형 생성 {#build-predictive-models}

```{r gdpr-predictive-model}
glm_spec <- linear_reg() %>%
  set_engine("lm") %>% 
  set_mode("regression")

gdpr_wf <- workflow() %>%
  add_recipe(gdpr_rec) %>%
  add_model(glm_spec) 

gdpr_fit <- fit(gdpr_wf, tidy_train) 
```

# 예측모형 평가 {#build-predictive-models-evaluate}

```{r gdpr-predictive-model-evaluate, eval = FALSE}

gdpr_fit %>%
  predict(tidy_test) %>%
  bind_cols(tidy_test) %>% 
  metrics(truth = price, estimate = .pred)


```

