---
layout: page
title: xwMOOC 모형
subtitle: "`tidymodels` - tidyverse 모형: `tidyverse` 성명서"
author:
  - name: "[Tidyverse Korea](https://www.facebook.com/groups/tidyverse/)"
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
    affiliation_url: https://www.facebook.com/groups/tidyverse/
date: "`r Sys.Date()`"
output:
  html_document: 
    include:
      after_body: footer.html
      before_body: header.html
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
bibliography: bibliography_model.bib
csl: biomed-central.csl
urlcolor: blue
linkcolor: blue
editor_options: 
  chunk_output_type: console
---
 

``` {r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')

```

# `tidyverse` 성명서 [^tidyverse-manifesto] {#tidyverse-manifesto}

[^tidyverse-manifesto]: [Hadley Wickham (2017-11-13), "The tidy tools manifesto"](https://cran.r-project.org/web/packages/tidyverse/vignettes/manifesto.html)

2017-11-13일 위캠(Hadley Wickham)은 `tidyverse` 성명서(manifesto)를 발표하였다.
엉망진창인 R 도구상자(messyverse)와 비교하여 깔끔한 R 도구상자(tidyverse)는 깔끔한(tidy) API에 다음과 같은 4가지 원칙을 제시하고,
기본적으로 `tidy` API에 필수적인 다음 원칙에 대한 준수를 당부하고 있다.

1. Reuse existing data structures; 기존 자료구조 재사용.
1. Compose simple functions with the pipe; 파이프(pipe)를 사용해서 단순한 함수를 조합.
1. Embrace functional programming; 함수형 프로그래밍을 적극 포용.
1. Design for humans; 인간을 위한 설계

## 기존 자료구조 재사용 {#tidyverse-manifesto-reuse-data-structure}

`ggplot2`, `dplyr`, `tidyr`을 포함한 많은 R 팩키지는 관측점과 변수로 구성된 직사각형 데이터셋(rectangular dataset)을 기반으로 돌아간다.
그렇다면 데이터프레임 혹은 티블(tibble)에서도 문제가 없을 것이다.

직사각형 데이터셋 외에 문자열은 `stringr`, 날짜/시간은 `lubridate`, 요인(factor)은 `forcats`를 주요한 기본 자료구조를 구성하게 된다.

## 파이프(pipe)를 사용해서 단순한 함수를 조합 {#tidyverse-manifesto-pipe}

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
</style>
<div class = "blue">

No matter how complex and polished the individual operations are, it is often the quality of the glue that most directly determines the power of the system.

- Hal Abelson 명언
</div>


파이프 연산자로 간단한 함수를 조합하여 시스템 전체의 힘을 극대화한다. 
복잡한 문제를 해결하는 강력한 전략은 단순한 많은 조각으로 나누고 이를 조합하는 것이다. 
단, 각 조각은 격리되어 쉽게 파악되고, 다른 조각과 조합할 수 있는 표준이 성립되어야 된다. 
R에 파이프 연산자를 사용하여 본 전략이 구현되어 있다. `%>%` 연산자는 많은 팩키지에 두루 걸쳐 동작되는 일반적인 결합 방식으로 이를 위해 함수를 작성할 때 다음 원칙을 갖고 작성한다.

- 함수를 가능하면 단순하게 작성한다. 일반적으로 각 함수는 한가지 작업을 매우 잘해야 되고, 한 문장으로 함수 존재목적을 기술할 수 있어야 된다.
- 변형(transformation)과 부작용(side-effect)을 뒤섞지 마라. 함수가 객체를 반환하거나, 부작용을 일으키거나 둘 중 하나만 동작하게 만든다.
- 함수명은 동사가 되어야 한다. 하지만, 예외로 대다수 함수가 동일한 동사를 사용한다. 예를 들어 `modify`, `add`, `compute` 등을 들 수 있다. 
이런 경우 반복되는 동사가 중복되지 않도록 명사에 집중한다. ggplot2가 좋은 예가 되는데 기존 플롯에 좌표, 점, 범례등을 거의 모든 함수가 추가하기 때문이다.

## 함수형 프로그래밍을 적극 포용 {#tidyverse-manifesto-functional-programming}


R은 함수형 언어라 객체지향언어나 다른 언어 패러다임과 싸우려고 하지 말고 받아들여라. 이것이 의미하는 바는 다음과 같다.

- 상태불변 객체: 작성된 코드에 대한 추론이 쉬움.
- S3, S4 에서 제공하는 제네릭 함수: 상태변형 가능한 상태가 필요하다면, 파이프 내부에서 구현.
- for 루프를 추상화한 도구: apply 함수 가족과 purrr 맵함수
- 데이터과학에서 병목점으로 문제가 발생되는 곳은 공통적으로 컴퓨터 실행시간(computing time)이 아니라 사람의 생각(thinking time)의 시간이다. 따라서, 함수명을 작성할 때 생각이 잘 연상되는 이름을 작명하는데 시간을 적절히 안분하고, 명시적이고 긴 명칭을 변수명, 함수명, 객체명에 사용하고, 짧은 명칭은 가장 중요한 이름으로 활용한다. RStudio 소스 편집기의 자동완성기능을 사용하는 경우 접두어가 접미어보다 중요하고, stringr,  xml2, rvest 팩키지를 살펴보면 접두어에 일관된 명칭을 부여한 장점을 알수 있다.

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 10px;}
</style>
<div class = "blue">

Programs must be written for people to read, and only incidentally for machines to execute.

- Hal Abelson 명언
</div>

## 인간을 위한 설계 {#tidyverse-manifesto-design-for-human}

API를 작성할 때 사람이 사용하기 쉽게 설계한다. 
데이터과학에서 병목점으로 문제가 발생되는 곳은 공통적으로 컴퓨터 실행시간(computing time)이 아니라 사람의 생각(thinking time)의 시간이다. 

- 함수명을 작성할 때 생각이 잘 연상되는 이름을 작명하는데 시간을 적절히 안분한다.
- 명시적이고 긴 명칭을 변수명, 함수명, 객체명에 사용하고, 짧은 명칭은 가장 중요한 이름으로 활용한다. 
- RStudio 소스 편집기의 자동완성기능을 사용하는 경우 접두어가 접미어보다 중요하고, stringr,  xml2, rvest 팩키지를 살펴보면 접두어에 일관된 명칭을 부여한 장점을 알수 있다.

<img src="fig/tidymodels-tidyverse.png" alt="tidyverse 모형" width="100%" />

# `tidyverse` 모형 - `tidymodels` {#tidyverse-modeling}

기존 10여년에 걸쳐 `catet` 팩키지가 담당했던 기능을 `tidyverse` 방식에 맞게 모형화도 깔끔(?)해지고 있다. 이를 위해서, 각각 기능별로 하나만 정말 잘 하는 팩키지들이 속속 출시되고 있다.
현재시점 기준 "2019-08-04" 몇몇 블로그를 통해서 개발되고 있는 최신 기능이 일부 소개되고 있다. [^blog-edgar] [^blog-datistics]

기계학습을 통한 일관된 인터페이스에 대한 요구는 파이썬 `scikit-learn`에 잘 나타나 있다. 어떻게 보면 R에서 파이썬 `scikit-learn`을 보면서 이에 대한 영감을 받아 시작되었는지도 모르겠다.

[^blog-edgar]: [Edgar Ruiz (2019-06-19), "A Gentle Introduction to tidymodels", R Views](https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/)

[^blog-datistics]: [datistics (December 29, 2018 ), "Tidymodels"](https://www.datisticsblog.com/2018/12/tidymodels/)

`tidymodels`은 통계검정과 모형 크게 두가지로 나눌 수 있는데 여기서는 우선 모형에 관련된 사항에 집중하기로 한다. 모형이 `tidyverse` 체계를 구성하는 핵심 사항임에도 불구하고 `dplyr`, `ggplot`과 비교하여 체계적으로 정리된 것이 없어 과거 `caret`이 했던 기능을 `tidymodels`를 통해 하나씩 채워나가고 있다. `tidymodels`를 구성하는 핵심 팩키지는 `rsample`, `recipes`, `parnip`, `yardstick`을 들 수 있다.

- [`tidymodels`](https://github.com/tidymodels/tidymodels)
    - 전처리와 피처 공학(Feature Engineering)
        - [`recipe`](https://github.com/tidymodels/recipes)(feature engineering): 모형 설계행렬 데이터를 생성하고 전처리하는 기능.
            - [`embed`](https://github.com/tidymodels/embed): 범주형 예측변수를 숫자 칼럼 예측변수로 담아내는 기능.
        - [`rsample`](https://github.com/tidymodels/rsample): 모형개발을 위한 표본추출 기능
        - [`themis`]()
    - 모형(Model)    
        - [`parsip`](https://topepo.github.io/parsnip/): 모형공식(formula) 표준화
    - 모형 미세조정(tuning)        
        - [`dials`](https://github.com/tidymodels/dials): 모형 초모수 튜닝 값 생성
        - [`tune`](https://github.com/tidymodels/tune): 모형 초모수 튜닝 도구
    - 성능평가(Evaluation)    
        - [`yardstick`](https://github.com/tidymodels/yardstick): 깔끔한 데이터(tidy data) 원칙에 따라 모형성능 추정.
    - 작업흐름(workflow)
        - [`workflows`](https://github.com/tidymodels/workflows)
    - 기타
        - `tidytext`
        - `broom`
        - `tidypredict`
        - `butcher`
        - `textrecipes`
        - `corrr`
- 통계 검정(Statistical Testing)        
    - [`tidyposterior`](https://tidymodels.github.io/tidyposterior/): 사후(post hoc) 모형 분석

# CART: `iris` 사례 {#iris-helloword}

![분류문제 - 작업흐름도](fig/tidymodels-iris.png)

## 탐색적 데이터 분석 {#iris-tidymodels-EDA}

탐색적 데이터 분석에 대해서 모형개발에 필요한 전반적인 사항은 모두 파악한다. 여기서는 `skimr` 팩키지로 붓꽃데이터에 대한 모든 사항을 파악한 것으로 갈음한다.

```{r iris-case-study-library-EDA}
skimr::skim(iris)
```

## `tidymodels` 도구 {#iris-tidymodels}

`tidymodels` 팩키지에 `tidyverse` 체계에서 예측모형을 구현하는 다양한 팩키지가 일괄적으로 포함되어 있다.

```{r iris-case-study-library}
library(tidymodels)
```

## 전처리와 피쳐 공학 {#iris-tidymodels-fe}

기계학습 예측모형을 개발할 때 훈련/시험 데이터로 쪼개고 피쳐 공학(Feature Engineering)을 통해 Basetable을 다양한 기계학습 알고리즘에 적합시키도록 사전 정지작업을 수행한다.

가장 먼저 `initial_split()` 함수로 훈련/시험 데이터를 7:3 비율로 쪼갠다. 특히 층화(`strata`)를 두어 7:3 비율이 정확히 유지되도록 지정한다.
`training()`, `testing()` 함수로 basetable 모형 데이터를 훈련/시험 데이터로 분리시킨다.

```{r iris-case-study}
iris_tbl <- iris %>% as_tibble %>% 
  janitor::clean_names()

iris_split <- initial_split(iris_tbl, prop = 0.7, strata = species)
iris_split

train_iris <- training(iris_split)
test_iris  <- testing(iris_split)
```

다음으로 `recipes` 팩키지를 사용해서 피쳐 공학 기법을 적용하여 다양한 기계학습 알고리즘을 적용시키도록 준비시킨다. `ggplot` 사용법에 익숙하신 분은 `recipes` 팩키지의 다양한 함수 사용법을 어려움 없이 사용할 수 있을 것이다.

`recipe()` 함수에 모형 공식을 작성하고, `step_*` 함수에 다양한 피처 공학 기법을 적용시켜 준비시킨다. 
만약 피처공학된 결과를 보고자 한다면 `iris_recipe %>% prep() %>% bake(new_data = train_iris)` 명령어로 레서피에 정의된 결과를 파악할 수 있다.

```{r iris-recipes-training-show}
iris_recipe <- recipe(species ~., data = train_iris) %>%
  step_center(all_predictors(), -all_outcomes()) %>%
  step_scale(all_predictors(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>% 
  prep()

summary(iris_recipe)
```

`iris_recipe` 요리법을 그대로 시험 데이터에 적용시켜 나중에 예측모형 성능평가에 사용한다. 
이때 사용되는 동사가 `bake()`로 구워둔다. 

```{r iris-recipes-testing}
iris_testdata <- iris_recipe %>% 
  prep() %>% 
  bake(new_data = test_iris)

glimpse(iris_testdata)
```


시험 데이터에 대한 전처리 및 피처 공학 적용이 완료되었다면, 다음 단계로 훈련 데이터에도 동일한 작업을 수행하는데 `juice()` 동사를 사용해서 해당 작업을 수행시키는데 이때 사용되는 요리법도 `iris_recipe`가 된다. 

`prep()`, `bake()`, `juice()` 동사로 중간중간 결과물을 파악한다.

```{r iris-recipes-training}
juice(iris_recipe) %>% 
  head()
```


## 모형지정 {#fit-model}

Random Forest 모형의 경우 `ranger`, `randomForest` 팩키지가 사실의 표준으로 학계와 산업계를 대표하고 있는데 인터페이스가 서로 달라 동일한 알고리즘임에도 불구하고 구문을 별도 작성해야 하는 어려움이 있는데 `parsnip`이 이를 표준화했다.
`rand_forest()`으로 모형을 정의하고 `set_engine()`에 팩키지명을 지정한다.

```{r iris-model}
iris_ranger <- rand_forest(trees = 100) %>%
  set_mode("classification") %>% 
  set_engine("ranger") # `ranger` 팩키지
  # set_engine("randomForest") %>% # `randomForest` 팩키지
```

## 예측모형 작업흐름 {#fit-model-workflow}

목적은 동일하지만 데이터 형태와 예측이냐 분류냐, 적용하고자 하는 예측모형에 따라 차이가 나더라도 `workflows`를 사용하면 앞선 예측모형 적용과정을 매우 단순화할 수 있다.

```{r iris-model-workflows}
library(workflows)

iris_workflow <- 
  workflow() %>% 
  add_model(iris_ranger) %>% 
  add_recipe(iris_recipe)
```

## 모형 적합 {#fit-model-workflow-fit}

`recipes` 단계에서 모형공식은 지정했기 때문에 `fit()` 함수 내부에 이를 중복해서 지정할 필요는 없다.

```{r iris-model-workflows-fit}
iris_fit <- iris_workflow %>% 
  fit(data = train_iris)

iris_fit
```

## 훈련데이터 - 예측 {#fit-model-predict-traing}

예측모형에 대한 성능을 파악하려면 예측값을 생성되어야 한다.
`predict()` 함수를 사용하게 되면 예측모형에 대한 예측값을 생성시킬 수 있는데 `broom` 팩키지와 마찬가지로 사용해서 `bind_cols()` 함수를 사용하게 되면 데이터프레임으로 후속 작업이 가능한 형태로 구현이 가능하다.

```{r iris-fit-predict-train}
iris_pred <- train_iris %>% 
  bind_cols(iris_fit %>% predict(train_iris)) %>% 
  bind_cols(iris_fit %>% predict(train_iris, type = "prob"))

head(iris_pred)
```

## 모형 성능 {#fit-model-performance}

`yardstic` 팩키지 `metrics()` 함수를 사용해서 예측모형의 성능을 파악할 수 있다.
먼저, `yardstick` 팩키지 `accuracy()` 함수로 정확도를 파악한다.

```{r iris-fit-predict-train-accuracy}
iris_pred %>% 
  accuracy(truth = species, estimate = .pred_class)
```

`conf_mat()` 함수를 사용해서 혼동행렬(confusion matrix)을 계산할 수 있다.

```{r iris-fit-predict-train-confusion}
iris_pred %>% 
  conf_mat(truth = species, estimate = .pred_class)
```

`metrics()` 함수를 사용하게 되면 특정 예측모형 측도를 지정하지 않고도 예측모형 성능에 대한 대략적인 정보를 획득할 수 있다.

```{r iris-fit-performance}
iris_pred %>%
  metrics(truth = species, estimate = .pred_class)
```

`iris` 데이터는 3가지 품종을 꽃에 대한 4가지 측정정보를 바탕으로 예측하는 것이라 보통 정확도만을 따지지만, `tidyverse`의 `dplyr`, `broom`을 사용한 경험이 있다면 각 범주별로 ROC, AUC를 계산하는 것도 수월하게 진행할 수 있다.

`gain_curve()`, `roc_curve()` 함수를 사용해서 이득(Gain), ROC 곡선도 코드 한줄로 작성이 가능하다.

```{r parsnip-performance-ggplot}
iris_pred %>%
  # gain_curve(species, .pred_setosa:.pred_virginica) %>%
  roc_curve(species, .pred_setosa:.pred_virginica) %>%
  autoplot()
```

마지막으로 예측모형 성능평가만을 위해서 추출한 성능평가지표(metrics)만 추출하여 데이터프레임으로 제작하여 성능지표에 대한 마무리를 한다.

```{r metric-concluded}
iris_pred %>% 
  metrics(species, .pred_setosa:.pred_virginica, estimate = .pred_class)
```

## 시험데이터 - 예측 {#fit-model-predict-test}

`predict()` 함수를 사용하게 되면 예측모형에 대한 예측값을 생성시킬 수 있는데 `broom` 팩키지와 마찬가지로 사용해서 `bind_cols()` 함수를 사용하게 되면 데이터프레임으로 후속 작업이 가능한 형태로 구현이 가능하다.

```{r iris-fit-predict}
test_pred <- test_iris %>% 
  bind_cols(iris_fit %>% predict(test_iris)) %>% 
  bind_cols(iris_fit %>% predict(test_iris, type = "prob"))

test_pred
```

`yardstick` 팩키지 `accuracy()` 함수로 시험데이터에 대한 정확도를 파악한다.

```{r iris-fit-predict-metrics}
test_pred %>% 
  accuracy(truth = species, estimate = .pred_class)
```

`conf_mat()` 함수를 사용해서 혼동행렬(confusion matrix)을 계산할 수 있다.

```{r iris-fit-predict-test-confusion}
test_pred %>% 
  conf_mat(truth = species, estimate = .pred_class)
```
